* [paper](paper/14.401-18-Context-Encoding-for-Semantic-Segmentation.pdf)
* [语义分割--(EncNet)Context Encoding for Semantic Segmentation](https://blog.csdn.net/u011974639/article/details/79806893)

### 动机

* 扩张卷积存在的问题
  * 先进的语义分割系统通常是基于FCN架构，采用的深度卷积神经网络受益于从不同图片中学习到的丰富的对象类别信息和场景语义。
  * CNN通过堆叠带非线性激活和下采样的卷积层能够捕获带全局接受野的信息表示，为了克服下采样带来的空间分辨率损失，最近的工作使用扩张卷积策略从预训练模型上产生密集预测。
  * 然而，此策略依然会将像素从全局场景上下文相隔开，这会导致像素错误分类。 如错误的将窗格分为门。
* 金字塔结构存在的问题

  * 近期的工作使用基于金字塔多分辨率表示扩大接受野。例如，PSPNet采用的PSP模块将特征图池化为不同尺寸，再做联接上采样；
  * DeepLab采用ASPP模块并行的使用大扩张率卷积扩大接受野。这些方法都有提升，但是这对上下文表示都不够明确，这出现了一个问题： 捕获上下文信息是否等同于增加接受野大小？

  * 如果我们能够先捕获到图像上下文信息(例如这是卧室)，然后，这可以提供许多相关小型目标的信息(例如卧室里面有床、椅子等)。这可以动态的减少搜索区域可能。说白了，这就是加入一个场景的先验知识进去，这样对图片中像素分类更有目的性。依照这个思路，可以设计一种方法，充分利用场景上下文和存在类别概率的之间的强相关性，这样语义分割会就容易很多。
* 通过传统图像方法引入图像全局上下文信息
  * 经典的计算机视觉方法具有捕获场景上下文语义的优点。例如SIFT提取密集特征或滤波器组响应密集提取图像特征。学习一个视觉字典，
  * BoW，VLAD和Fish Vector通过类别编码描述特征统计信息。
  *  经典表示通过捕获特征统计信息编码全局信息，虽然手工提取特征通过CNN方法得到了很大的改进，但传统方法的总体编码过程更为方便和强大。
* 最近有工作在CNN框架中推广传统编码器方法获得了极大的进步，Zhao等人引入了一个编码层将整个字典学习和残差编码管道集成到CNN层中用于捕获无序表示(orderless)。这在纹理分类任务上达到了state-of-the-art，在本文中，使用扩展编码层用于捕获全局特征的统计信息用于理解上下文语义。

* **Featuremap Attention and Scaling**：

  * 逐通道式的特征attention是受到其他工作启发。 Spatial Transformer Network在没有额外监督的条件下在网络内部学习了空间变换。Batch Normalization 是的小批量数据的均值和方差作为网络的一部分做标准化，成功的允许使用更大的学习率，并使得网络对初始方法不是那么敏感。
  * 最近在风格转换方面的工作处理特征图均值和方差或二阶统计信息用于启动网络内部风格变换。SE-Net探究了跨通道信息以学习逐通道attention。
  * 受这些方法启发，论文使用以编码语义预测特征图通道的放缩因子，这提供了在给定场景上下文的情况下强调个别特征图的机制。

### 创新

1. 引入了上下文编码模块，该单元用于捕获全局场景上下文信息和选择性的突出于类别相关的特征图。

   * 集成了语义编码损失(Semantic Encoding Loss,SE-loss)。 举例来讲，我们不考虑车辆出现在卧室的可能性，在现有标准的训练过程使用的是像素分割损失，这不强调场景的全局信息。
   * 我们引入语义编码损失(SE-loss)可进一步规范网络训练，让网络预测能够预测场景中对象类别的存在，强化网络学习上下文语义。 
   * 与逐像素的损失不同，SE-Loss对于大小不同的物体有相同的贡献，在实践中这能够改善识别小物体的表现，这里提出的上下文编码模块和语义编码损失在概念上是直接的并且和现存的FCN方法是兼容的。

2. 设计了一个新的语义分割架构Context Encoding Network (EncNet)，EncNet通过上下文编码模块增强了预训练的ResNet。

3. 论文采用了扩张卷积策略，在PASCAL VOC 2012 上达到了85.9% mIoU，PASCAL-Context上达到了51.7%；单模型的EncNet-101在ADE20K上达到了0.5567，这超过了2017年冠军。 
   * 此外，论文还CIFAR-10上测试了上下文编码模块的功能，使用上下文编码模块能够显著的提升浅层网络的性能，在只有3.5M参数的条件下达到了3.96%的错误率。 同时论文发布了完整的系统实现，包括多GPU同步BN和内存高效编码层。

### 方法

#### Context Encoding Module

* 结构：

![这里写图片描述](readme/14.401-context_encode_module.png)

* **Context Encoding：**

  * 对于预训练网络，使用编码层捕获特征图的统计信息作为全局上下文语义，将编码层的输出作为编码语义(encoded semantics)，为了使用上下文，预测了一组放缩因子(scaling factors)用于突出和类别相关的特征图。编码层学习带有上下文语义的固有字典，输出丰富上下文信息的残差编码。 这里简单描述一下编码层工作。


  ![1541748401604](readme/14.401-context_encode_公式.png)

* **Featuremap Attention：**

  * 为了使用编码层捕获的编码语义，我们预测一组特征图的放缩因子作为循环用于突出需要强调的类别。
  * 在编码层端上使用FC层，使用sigmoid作为激活函数，预测特征图的放缩因子γ=δ(We)，其中W表示层的权重，δ表示sigmoid激活函数。模块通过Y=X⊗γ得到输出，每个通道在特征图XX和放缩因子γ之间做逐像素相乘。 
  * 这样的方法受SE-Net等工作的启发，即考虑强调天空出现飞机，不强调出现车辆的可能性。

* **Semantic Encoding Loss：**
  * 标准的语义分割训练过程，使用的是逐像素的交叉熵，这将像素独立开学习。这样网络在没有全局上下文情况下可能会难以理解上下文，为了规范上下文编码模块的训练过程，使用Semantic Encoding Loss (SE-loss)在添加少量额外计算消耗的情况下强制网络理解全局语义信息。
  * 在编码层之上添加了一个带Sigmoid激活的FC层用于单独预测场景中出现的目标类别，并学习二进制交叉熵损失。不同于逐像素损失，SE loss 对于大小不同的目标有相同的贡献，这能够提升小目标的检测性能。

#### Context Encoding Network (EncNet):

* 在提出的上下文编码模块基础上，基于使用了扩张策略的预训练ResNet构建了Context Encoding Network (EncNet)。 细节如下图所示

![这里写图片描述](readme/14.401-context_encode_network_网络框架.png)

* 扩张卷积策略： 在stage3使用了扩张率为2，stage4扩张率为4。
* 为了进一步的提升和规范上下文编码模块的训练，使用了单独的分离分支用于最小化SE-loss，该Loss采用已编码的语义作为输入并预测对象类别的存在。
* 因为上下文模块和SE-loss是轻量级的，论文在stage3上端添加另一个上下文编码模块用于最小化SE-loss作为额外的正则化，这类比于PSPNet的辅助分支但比那个轻量了许多。
* SE-loss的ground truth是从真实的ground-truth分割mask上直接生成的。
* 上下文编码模块插入到现存的CNN模型上是不需要额外的修正和监督的。

### 数据集

* voc： 85.9% mIoU

###  实验

* 在voc上的表现，结果对比

![1541750524840](readme/14.401-实验_01.png)

* 实验效果

![1541750611699](readme/14.401-实验_02.png)